## 📘 **전체 실험 개요 및 요약**

### 🔍 **실험 목적**
> 뉴스 기사 데이터를 기반으로 **추상적 요약(Seq2Seq 모델)**과 **추출적 요약(Summa)**을 비교하고, 다양한 자동화 지표(BLEU, ROUGE)와 **키워드 기반 평가 방식**을 통해 모델 성능을 다각도로 분석한다.

---

### 🧱 **실험 구성**

| 단계 | 내용 |
|------|------|
| **1️⃣ 데이터 준비** | 뉴스 기사 원문(`text`)과 정답 요약(`headlines`)을 포함한 데이터셋 확보 |
| **2️⃣ 데이터 전처리 (추상적 요약용)** | - 텍스트 정제 및 정규화<br>- 단어 수 제한, 토크나이징, 희귀 단어 제거 등<br>- 희귀 단어 비율, 등장 빈도 시각화로 Threshold 선정 |
| **3️⃣ 어텐션 메커니즘 적용 모델 구현** | - Seq2Seq + Attention 모델 구성<br>- LSTM 기반 인코더-디코더에 어텐션 레이어 통합 |
| **4️⃣ 실제 결과와 정답 요약 비교** | - 추상적 요약 생성 후, 정답 요약과 비교<br>- BLEU, ROUGE-L 등 **정량적 평가** 수행 |
| **5️⃣ Summa(TextRank)로 추출적 요약 수행** | - 전처리 없이 원문을 입력으로 사용<br>- 핵심 문장 자동 추출하여 요약 생성 |
| **6️⃣ 추상 vs 추출 요약 비교** | - BLEU/ROUGE 정량 비교<br>- **Keyword Inclusion / Recall / Content Fidelity**로 내용 보존력 평가<br>- 상위/하위 샘플 비교, 시각화 분석 |
| **7️⃣ 성능 향상을 위한 개선 전략 탐색** | - 모델 개선 전략 제안: Copy Mechanism, Coverage, Beam Search 등<br>- 학습 안정화 기법: Dropout, Gradient Clipping, Scheduler 등 |
| **8️⃣ 회고 및 정리** | - 시행착오: 데이터 인덱스 불일치, 전처리 오류<br>- 학습 성과: 요약 방식별 특성 이해, 다양한 평가 방식 적용 능력 향상 |

---

### ⚠️ **주요 시행착오 및 교훈**

1. **데이터 인덱스 불일치 → 유사도 기반 매칭 필요**
2. **Summa 모델은 전처리 시 성능 하락 → 전처리 생략 필수**
3. **단순 지표 외에도 키워드 기반 평가가 정보 보존 측면에서 효과적**

---

### 🧠 **결과 요약 및 인사이트**

| 모델 | BLEU/ROUGE | 핵심 단어 포함률 | 특이점 |
|------|------------|------------------|--------|
| **Seq2Seq** | BLEU 낮음, ROUGE 일부 ↑ | 키워드 포함률 낮음 | 추상적 문장 생성 능력은 있으나 정보 보존 약함 |
| **Summa** | ROUGE 전반적으로 우수 | 키워드 포함률 높음 | 문장 구성은 투박하지만 정보 보존에 강함 |

> ✅ **추상 요약은 문장 생성력**, **추출 요약은 정보 보존력**  
> → **어플리케이션 목적에 따라 선택 혹은 결합 전략 고려 필요**

---

### 🚀 **향후 개선 방향 (모델 관점)**

- **Copy Mechanism**, **Coverage Attention**, **Keyword-aware Loss** 등 정보 보존력 강화 모델 구조 도입
- **Beam Search**, **Bidirectional LSTM**, **Pre-trained Embedding** 등 정밀도 향상 구조 개선
- **Keyphrase 기반 평가 방식 지속 적용 → 평가 신뢰도 제고**

